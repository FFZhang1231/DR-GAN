#coding:utf-8
import tensorflow as tf
from ops import *
import tensorflow.examples.tutorials.mnist.input_data as input_data
from PIL import  Image
import pandas as pd
#数据处理
#mnist = input_data.read_data_sets("MNIST_data/", one_hot=True)
batch_size = 200
epoch = 5
imglist = np.loadtxt('input.txt',dtype='string',delimiter=' ')
image_path = '/home/pris/Videos/session01/'
pose_dict = dict(zip(['041','050','051','080','130','140','190'],range(7)))
#占位符
inputs = tf.placeholder(tf.float32,[batch_size,60,60,1],name='real_images')#输入图片
y = tf.placeholder(tf.int64, [batch_size], name='y')#输入图片标签
z = tf.placeholder(tf.float32, [batch_size,20], name='z')#生成器噪声向量
dis_pose = tf.placeholder(tf.int64, [batch_size], name='pose')#判别器姿态向量
gen_pose = tf.placeholder(tf.int64, [batch_size], name='pose')#生成器姿态向量
gen_pose_onehot = tf.one_hot(gen_pose,7)
#取数据
def get_batch(idx):
    temp = imglist[idx:idx+batch_size]
    batch_images = np.zeros((batch_size,60,60,1))
    for i in range(temp.shape[0]):
        img = Image.open(image_path+temp[i,0])
        array_img = np.array(img)
        batch_images[i,:,:,0] = (array_img - array_img.mean())/array_img.std()
    batch_labels = temp[:,1].astype('int')
    temp=pd.DataFrame(temp)
    batch_dis_pose = temp[3].apply(lambda x:pose_dict[x]).values
    batch_gen_pose = temp[2].apply(lambda x:pose_dict[x]).values
    return batch_images,batch_labels-1,batch_dis_pose,batch_gen_pose
#定义生成器和判别器
def generator(z, image,pose,reuse=False):
    with tf.variable_scope("Generator",reuse=reuse) as scope:
        h10 = tf.nn.relu(bn(conv2d(image,filters=32,kernel_size=3)))
        h11 = tf.nn.relu(bn(conv2d(h10,filters=64,kernel_size=3)))
        h12 = tf.nn.relu(bn(conv2d(h11,filters=64,kernel_size=3,strides=[2,2])))      
        h13 = tf.nn.relu(bn(conv2d(h12,filters=64,kernel_size=3)))
        h14 = tf.nn.relu(bn(conv2d(h13,filters=128,kernel_size=3)))
        h15 = tf.nn.relu(bn(conv2d(h14,filters=128,kernel_size=3,strides=[2,2])))
        h16 = tf.nn.relu(bn(conv2d(h15,filters=128,kernel_size=3)))
        h17 = tf.nn.relu(bn(conv2d(h16,filters=96,kernel_size=3)))
        h18 = tf.nn.relu(bn(conv2d(h17,filters=192,kernel_size=3,strides=[2,2])))
        h19 = tf.nn.relu(bn(conv2d(h18,filters=128,kernel_size=3)))
        h110 = tf.nn.relu(bn(conv2d(h19,filters=160,kernel_size=3)))
        avg_pool1 = tf.reshape(tf.layers.average_pooling2d(h110,pool_size=7,strides=7),[-1,160])
        gen_middle = tf.concat([avg_pool1,z,pose],1)
        fc1 = tf.layers.dense(gen_middle,units=9408,
            kernel_initializer=tf.truncated_normal_initializer(stddev=0.01))
        g10 = tf.nn.relu(bn(deconv2d(tf.reshape(fc1,[-1,7,7,192]),
            filters=128,kernel_size=3)))
        g11 = tf.nn.relu(bn(deconv2d(g10,filters=192,kernel_size=3)))
        g12 = tf.nn.relu(bn(deconv2d(g11,filters=192,kernel_size=3,
            strides=[2,2],padding='valid')))
        g13 = tf.nn.relu(bn(deconv2d(g12,filters=96,kernel_size=3)))
        g14 = tf.nn.relu(bn(deconv2d(g13,filters=128,kernel_size=3)))
        g15 = tf.nn.relu(bn(deconv2d(g14,filters=128,kernel_size=3,strides=[2,2])))
        g16 = tf.nn.relu(bn(deconv2d(g15,filters=64,kernel_size=3)))
        g17 = tf.nn.relu(bn(deconv2d(g16,filters=64,kernel_size=3)))
        g18 = tf.nn.relu(bn(deconv2d(g17,filters=64,kernel_size=3,strides=[2,2])))
        g19 = tf.nn.relu(bn(deconv2d(g18,filters=32,kernel_size=3)))
        g110 = tf.nn.relu(bn(deconv2d(g19,filters=1,kernel_size=3)))
        generate = tf.nn.tanh(g110)
        return generate
            
def discriminator(image, reuse=False):
    with tf.variable_scope("Discriminator",reuse=reuse) as scope:
        h10 = tf.nn.relu(bn(conv2d(image,filters=32,kernel_size=3)))
        h11 = tf.nn.relu(bn(conv2d(h10,filters=64,kernel_size=3)))
        h12 = tf.nn.relu(bn(conv2d(h11,filters=64,kernel_size=3,strides=[2,2])))      
        h13 = tf.nn.relu(bn(conv2d(h12,filters=64,kernel_size=3)))
        h14 = tf.nn.relu(bn(conv2d(h13,filters=128,kernel_size=3)))
        h15 = tf.nn.relu(bn(conv2d(h14,filters=128,kernel_size=3,strides=[2,2])))
        h16 = tf.nn.relu(bn(conv2d(h15,filters=128,kernel_size=3)))
        h17 = tf.nn.relu(bn(conv2d(h16,filters=96,kernel_size=3)))
        h18 = tf.nn.relu(bn(conv2d(h17,filters=192,kernel_size=3,strides=[2,2])))
        h19 = tf.nn.relu(bn(conv2d(h18,filters=128,kernel_size=3)))
        h110 = tf.nn.relu(bn(conv2d(h19,filters=160,kernel_size=3)))
        avg_pool1 = tf.layers.average_pooling2d(h110,pool_size=7,strides=7)
        avg_pool1_flat = tf.reshape(avg_pool1,[batch_size,160])
        logits_id = tf.layers.dense(avg_pool1_flat,
            units=100,kernel_initializer=tf.truncated_normal_initializer(stddev=0.01))
        logits_pose = tf.layers.dense(avg_pool1_flat,
            units=7,kernel_initializer=tf.truncated_normal_initializer(stddev=0.01))
        logits_real = tf.nn.sigmoid(tf.layers.dense(avg_pool1_flat,
            units=1,kernel_initializer=tf.truncated_normal_initializer(stddev=0.01)))
        return logits_id,logits_pose,logits_real
#构建生成器和判别器
G = generator(z,inputs,gen_pose_onehot)
D_id,D_pose,D_real = discriminator(inputs)
D_G_id,D_G_pose,D_G_real = discriminator(G,reuse=True)
#损失函数
d_loss_id = tf.losses.sparse_softmax_cross_entropy(labels=y,logits=D_id)
d_loss_pose = tf.losses.sparse_softmax_cross_entropy(labels=dis_pose,logits=D_pose)
d_loss_gan = -tf.reduce_mean(tf.log(D_real) + tf.log(1. - D_G_real))
d_loss = d_loss_pose+d_loss_id+d_loss_gan
g_loss_id = tf.losses.sparse_softmax_cross_entropy(labels=y,logits=D_G_id)
g_loss_pose = tf.losses.sparse_softmax_cross_entropy(labels=gen_pose,logits=D_G_pose)
g_loss_gan = -tf.reduce_mean(tf.log(D_G_real))
g_loss = g_loss_gan+g_loss_pose+g_loss_id
#
t_vars = tf.trainable_variables()
d_vars = [var for var in t_vars if 'D' in var.name]
g_vars = [var for var in t_vars if 'G' in var.name]
saver = tf.train.Saver()
#网络优化
d_optim = tf.train.AdamOptimizer(learning_rate=0.01).minimize(d_loss,var_list=d_vars)
g_optim = tf.train.AdamOptimizer(learning_rate=0.01).minimize(g_loss,var_list=g_vars)
#训练&测试
sess=tf.InteractiveSession()  
sess.run(tf.global_variables_initializer())
loss = 0
for i in range(epoch):
    for j in range(980):
        batch_z = np.random.uniform(-1, 1, [batch_size, 20]).astype(np.float32)
        batch_images,batch_labels,batch_dis_pose,batch_gen_pose=get_batch(j)
        _,loss1,_,loss2 = sess.run([g_optim,g_loss,d_optim,d_loss],
                feed_dict={ 
                  inputs: batch_images,
                  z: batch_z,
                  y:batch_labels,
                  dis_pose:batch_dis_pose,
                  gen_pose:batch_gen_pose
                })

        print('Generator loss:%f' % loss1)
        print('Discriminator loss:%F' % loss2)
sess.close()





